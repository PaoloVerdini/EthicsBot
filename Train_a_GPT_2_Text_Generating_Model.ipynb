{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Train_a_GPT_2_Text_Generating_Model_w_GPU.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"H7LoMj4GA4n_"},"source":["#  Train a GPT-2 Text-Generating Model w/ GPU For Free \n","\n","by [Max Woolf](http://minimaxir.com)\n","\n","*Last updated: November 10th, 2019*\n","\n","Retrain an advanced text generating neural network on any text dataset **for free on a GPU using Collaboratory** using `gpt-2-simple`!\n","\n","For more about `gpt-2-simple`, you can visit [this GitHub repository](https://github.com/minimaxir/gpt-2-simple). You can also read my [blog post](https://minimaxir.com/2019/09/howto-gpt2/) for more information how to use this notebook!\n","\n","\n","To get started:\n","\n","1. Copy this notebook to your Google Drive to keep it and save your changes. (File -> Save a Copy in Drive)\n","2. Make sure you're running the notebook in Google Chrome.\n","3. Run the cells below:\n"]},{"cell_type":"code","metadata":{"id":"KBkpRgBCBS2_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637333319670,"user_tz":420,"elapsed":100159,"user":{"displayName":"Paolo Verdini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5rOvBH3Z1IIZTEbIoKWAaKG0XkOwI2nfdUeG5lw=s64","userId":"02285138175827045307"}},"outputId":"56e86f58-8c49-4e27-f329-737c22425bef"},"source":["%tensorflow_version 1.x\n","!pip install -q gpt-2-simple\n","import gpt_2_simple as gpt2\n","from datetime import datetime\n","from google.colab import files"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow 1.x selected.\n","\u001b[K     |████████████████████████████████| 489.6 MB 23 kB/s \n","\u001b[K     |████████████████████████████████| 5.8 MB 34.1 MB/s \n","\u001b[K     |████████████████████████████████| 463 kB 43.0 MB/s \n","\u001b[K     |████████████████████████████████| 1.3 MB 40.1 MB/s \n","\u001b[?25h  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"markdown","metadata":{"id":"Bj2IJLHP3KwE"},"source":["## GPU\n","\n","Colaboratory uses either a Nvidia T4 GPU or an Nvidia K80 GPU. The T4 is slightly faster than the old K80 for training GPT-2, and has more memory allowing you to train the larger GPT-2 models and generate more text.\n","\n","You can verify which GPU is active by running the cell below."]},{"cell_type":"code","metadata":{"id":"sUmTooTW3osf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637333319670,"user_tz":420,"elapsed":18,"user":{"displayName":"Paolo Verdini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5rOvBH3Z1IIZTEbIoKWAaKG0XkOwI2nfdUeG5lw=s64","userId":"02285138175827045307"}},"outputId":"901824f4-f15a-4bee-d487-e3a55a7872d7"},"source":["!nvidia-smi"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Nov 19 14:48:39 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   31C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","metadata":{"id":"0wXB05bPDYxS"},"source":["## Downloading GPT-2\n","\n","If you're retraining a model on new text, you need to download the GPT-2 model first. \n","\n","There are three released sizes of GPT-2:\n","\n","* `124M` (default): the \"small\" model, 500MB on disk.\n","* `355M`: the \"medium\" model, 1.5GB on disk.\n","* `774M`: the \"large\" model, cannot currently be finetuned with Colaboratory but can be used to generate text from the pretrained model (see later in Notebook)\n","* `1558M`: the \"extra large\", true model. Will not work if a K80 GPU is attached to the notebook. (like `774M`, it cannot be finetuned).\n","\n","Larger models have more knowledge, but take longer to finetune and longer to generate text. You can specify which base model to use by changing `model_name` in the cells below.\n","\n","The next cell downloads it from Google Cloud Storage and saves it in the Colaboratory VM at `/models/<model_name>`.\n","\n","This model isn't permanently saved in the Colaboratory VM; you'll have to redownload it if you want to retrain it at a later time."]},{"cell_type":"code","metadata":{"id":"P8wSlgXoDPCR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637333377585,"user_tz":420,"elapsed":57925,"user":{"displayName":"Paolo Verdini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5rOvBH3Z1IIZTEbIoKWAaKG0XkOwI2nfdUeG5lw=s64","userId":"02285138175827045307"}},"outputId":"d44b3495-2f0a-4cdc-e274-757793741b51"},"source":["gpt2.download_gpt2(model_name=\"124M\")"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["Fetching checkpoint: 1.05Mit [00:00, 451Mit/s]                                                      \n","Fetching encoder.json: 1.05Mit [00:00, 1.62Mit/s]\n","Fetching hparams.json: 1.05Mit [00:00, 249Mit/s]                                                    \n","Fetching model.ckpt.data-00000-of-00001: 498Mit [00:52, 9.47Mit/s]\n","Fetching model.ckpt.index: 1.05Mit [00:00, 478Mit/s]                                                \n","Fetching model.ckpt.meta: 1.05Mit [00:00, 1.91Mit/s]\n","Fetching vocab.bpe: 1.05Mit [00:00, 1.89Mit/s]\n"]}]},{"cell_type":"markdown","metadata":{"id":"N8KXuKWzQSsN"},"source":["## Mounting Google Drive\n","\n","The best way to get input text to-be-trained into the Colaboratory VM, and to get the trained model *out* of Colaboratory, is to route it through Google Drive *first*.\n","\n","Running this cell (which will only work in Colaboratory) will mount your personal Google Drive in the VM, which later cells can use to get data in/out. (it will ask for an auth code; that auth is not saved anywhere)"]},{"cell_type":"code","metadata":{"id":"puq4iC6vUAHc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637333405617,"user_tz":420,"elapsed":28043,"user":{"displayName":"Paolo Verdini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5rOvBH3Z1IIZTEbIoKWAaKG0XkOwI2nfdUeG5lw=s64","userId":"02285138175827045307"}},"outputId":"f5dc76b3-017c-43e0-f56e-47b1a16c7af7"},"source":["gpt2.mount_gdrive()"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"BT__brhBCvJu"},"source":["## Uploading a Text File to be Trained to Colaboratory\n","\n","In the Colaboratory Notebook sidebar on the left of the screen, select *Files*. From there you can upload files:\n","\n","![alt text](https://i.imgur.com/TGcZT4h.png)\n","\n","Upload **any smaller text file**  (<10 MB) and update the file name in the cell below, then run the cell."]},{"cell_type":"code","metadata":{"id":"6OFnPCLADfll","executionInfo":{"status":"ok","timestamp":1637333585895,"user_tz":420,"elapsed":347,"user":{"displayName":"Paolo Verdini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5rOvBH3Z1IIZTEbIoKWAaKG0XkOwI2nfdUeG5lw=s64","userId":"02285138175827045307"}}},"source":["file_name = \"all_ai_novels.txt\""],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HeeSKtNWUedE"},"source":["If your text file is larger than 10MB, it is recommended to upload that file to Google Drive first, then copy that file from Google Drive to the Colaboratory VM."]},{"cell_type":"code","metadata":{"id":"-Z6okFD8VKtS"},"source":["gpt2.copy_file_from_gdrive(file_name)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LdpZQXknFNY3"},"source":["## Finetune GPT-2\n","\n","The next cell will start the actual finetuning of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`. (to have the finetuning run indefinitely, set `steps = -1`)\n","\n","The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every 500 steps (can be changed) and when the cell is stopped.\n","\n","The training might time out after 4ish hours; make sure you end training and save the results so you don't lose them!\n","\n","**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files.\n","\n","Other optional-but-helpful parameters for `gpt2.finetune`:\n","\n","\n","*  **`restore_from`**: Set to `fresh` to start training from the base GPT-2, or set to `latest` to restart training from an existing checkpoint.\n","* **`sample_every`**: Number of steps to print example output\n","* **`print_every`**: Number of steps to print training progress.\n","* **`learning_rate`**:  Learning rate for the training. (default `1e-4`, can lower to `1e-5` if you have <1MB input data)\n","*  **`run_name`**: subfolder within `checkpoint` to save the model. This is useful if you want to work with multiple models (will also need to specify  `run_name` when loading the model)\n","* **`overwrite`**: Set to `True` if you want to continue finetuning an existing model (w/ `restore_from='latest'`) without creating duplicate copies. "]},{"cell_type":"code","metadata":{"id":"aeXshJM-Cuaf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637337991032,"user_tz":420,"elapsed":4380406,"user":{"displayName":"Paolo Verdini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5rOvBH3Z1IIZTEbIoKWAaKG0XkOwI2nfdUeG5lw=s64","userId":"02285138175827045307"}},"outputId":"9879851d-0d27-4ccc-acec-a16092583b4a"},"source":["sess = gpt2.start_tf_sess()\n","\n","gpt2.finetune(sess,\n","              dataset=file_name,\n","              model_name='124M',\n","              steps=1000,\n","              restore_from='fresh',\n","              run_name='run1_novels',\n","              print_every=10,\n","              sample_every=200,\n","              save_every=500\n","              )"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading checkpoint models/124M/model.ckpt\n","INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n","Loading dataset...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1/1 [00:14<00:00, 14.71s/it]\n"]},{"output_type":"stream","name":"stdout","text":["dataset has 2550816 tokens\n","Training...\n","[10 | 47.20] loss=2.94 avg=2.94\n","[20 | 89.61] loss=2.88 avg=2.91\n","[30 | 132.66] loss=3.17 avg=3.00\n","[40 | 176.04] loss=2.94 avg=2.98\n","[50 | 218.84] loss=2.98 avg=2.98\n","[60 | 261.14] loss=2.80 avg=2.95\n","[70 | 303.40] loss=2.99 avg=2.96\n","[80 | 345.78] loss=3.17 avg=2.98\n","[90 | 388.01] loss=2.70 avg=2.95\n","[100 | 430.24] loss=3.24 avg=2.98\n","[110 | 472.47] loss=2.85 avg=2.97\n","[120 | 514.69] loss=2.39 avg=2.92\n","[130 | 556.99] loss=2.44 avg=2.88\n","[140 | 599.27] loss=2.52 avg=2.85\n","[150 | 641.55] loss=2.42 avg=2.82\n","[160 | 683.82] loss=2.67 avg=2.81\n","[170 | 726.04] loss=3.27 avg=2.84\n","[180 | 768.35] loss=2.87 avg=2.84\n","[190 | 810.45] loss=2.96 avg=2.85\n","[200 | 852.89] loss=2.84 avg=2.85\n","======== SAMPLE 1 ========\n"," than as many in the world, I have only one hope: to become a respectable person.\"\n","\n","For once, the two brothers, sitting together in a corner, were alone.\n","\n","\n","\n","When the first man had been dressed in a uniform that covered most of the room, and the second had been dressed in his customary outfit, the three of them were together. He had been taken out of the room, with a large suitcase and a penknife. A few minutes later, two of them would be standing close together in the lobby. The man in the pocket of a jacket and shirt, his eyes glowing with the sun, had appeared as if looking up.\n","\n","\n","\n","On a recent evening, after a night of drinking, the men of the club had settled into the fifth floor to chat and discuss affairs. The clubmaster had retired, leaving Michael, Nick, and Victor in their room to talk to a woman. This woman had taken the name Michael and wished to remain anonymous.\n","\n","\n","\n","Instead, an expression of concern arose from the woman—who looked nothing like her real name—in the lobby.\n","\n","It dawned on them that at least Michael had taken a female as his bride, with whom he and Nick were having a happy birthday in New York City. Nick, he knew for sure, had not been there and still the girl was looking like a woman. The man in the pocket of a jacket and shirt, though he had never been there before, had already made his way up to the corner and looked like he might look like the man in the hotel room.\n","\n","The man in the hotel room had been surprised to find himself in the middle of conversation with one of the others, and had begun looking for them in a darkened corner.\n","\n","\"Where are you?\" he said.\n","\n","\"I have a room in a place I've never seen before, and I wanted to talk to you,\" Nick said.\n","\n","\"What's that?\"\n","\n","\"It's a meeting of people, Nick.\"\n","\n","\"All the guests are there? That's all.\"\n","\n","Nick had waited outside the corner, waiting to find the hotel manager. His tone was not at all serious but a kind of a warning.\n","\n","\"You mean I can't have a chat with you now?\"\n","\n","\"No. I have plenty of time, Nick.\"\n","\n","\"I don't think this meeting can go on for long, but it's been going on for a long time. It looks like we must meet again soon.\"\n","\n","\"We need to do it now, Mr. Suckling, and ask our next question. We need to discuss this quickly, we don't need to be distracted by people, the meeting is over and we don't need any further trouble.\"\n","\n","\"I won't let him get away,\" Nick said.\n","\n","\"You will, Mr. Suckling?\" he asked.\n","\n","\"Yes, and you will.\"\n","\n","\"So you want to see me?\"\n","\n","\"No, Nick,\" she said. \"I want your help on things and I can talk to everyone before I can say a word.\"\n","\n","\"But you will ask me. I am an idiot.\"\n","\n","\"That seems to be a good thing to say, Mr. Suckling. We can learn from each other. You have nothing to say.\"\n","\n","\"I do, Nick. We know I am an idiot.\"\n","\n","\"And now he's got one of those giant brains that doesn't even let me speak. What happens then, Mr. Suckling? When he does nothing? So I'm going to have to see some of him or leave. You're a dick, but you're still the same person I was before he got hurt, right. It's the end of the world and I can't be a good dad. I've got to live and die. The world is changing. I can't be a good dad. I've got to live and die.\"\n","\n","She saw the man's face. A long line of blood appeared from his mouth.\n","\n","\"Sorry for being late,\" she said, pulling up a little more courage, \"I thought the party was over.\"\n","\n","\"But no, not yet,\" Nick said, \"I have to have some fun in the morning and eat some breakfast.\"\n","\n","\"And I can't talk to anyone until I take the girl out of the lobby with my penknife,\" she said.\n","\n","She then took another penknife without leaving the room and used it to plunge a half-pound of the girl into one of the other women's arms.\n","\n","Once inside, however, she found an empty room, as though she had been watching all night, a half-empty house. It looked so much like a warehouse in the world now, but it had been a warehouse for centuries, not long since the day the Victor and Nick met. She stood in\n","\n","[210 | 916.32] loss=2.86 avg=2.85\n","[220 | 959.59] loss=2.33 avg=2.82\n","[230 | 1002.88] loss=2.88 avg=2.82\n","[240 | 1046.22] loss=2.78 avg=2.82\n","[250 | 1089.58] loss=2.61 avg=2.81\n","[260 | 1132.99] loss=2.77 avg=2.81\n","[270 | 1176.30] loss=2.82 avg=2.81\n","[280 | 1219.61] loss=3.05 avg=2.82\n","[290 | 1262.86] loss=2.37 avg=2.80\n","[300 | 1305.87] loss=3.20 avg=2.82\n","[310 | 1348.74] loss=2.42 avg=2.80\n","[320 | 1391.99] loss=2.88 avg=2.81\n","[330 | 1435.34] loss=2.82 avg=2.81\n","[340 | 1478.70] loss=3.16 avg=2.82\n","[350 | 1522.00] loss=2.45 avg=2.81\n","[360 | 1565.29] loss=2.65 avg=2.80\n","[370 | 1608.54] loss=3.15 avg=2.81\n","[380 | 1651.35] loss=2.75 avg=2.81\n","[390 | 1693.84] loss=2.74 avg=2.81\n","[400 | 1736.26] loss=2.68 avg=2.81\n","======== SAMPLE 1 ========\n"," heaven, and where I was; I was a beggar in disguise, a fiend in disguise, and I was in the dark. And so it is now. They must take away as much as I am capable of without, I suspect, that they may leave the land to have none of the more remarkable features of this world. The last thing that must come to me on this occasion is the triumph of any man who, in the hope, which he holds for himself, must come to me. Not for me alone are I to be the maker of all. There is another world for me to come into.\n","\n","\t\t\tThe next morning, a messenger was sent to my father, the merchant, when he learned from me that he was about to leave for London some time before the time for the sack-market had yet passed. If it had been, I might have been there. I had heard his tale now, and it was true. In this case it was clear to me that I should have gone, as my father had been at first; and that no one would ever have dared to claim me. Now I thought I should do the same, but I should have gone and found myself dead. What I was, I must have made.\n","\n","\t\t\tThe messenger brought an iron box from near him, and he opened it, and placed it on a table next to the one for which I had been sent to pick up Mr. Walton.\n","\n","\t\t\tHere he took the body of my father, and proceeded to the house. I could only think of the great burden which he took; and my father said: If you could be at peace at the present day, sir, I believe, by leaving London alone, I would do it not in my own person only, but also, with these other bodies, that I left at my father—\n","\n","JUSTINE: What you call a murderer?\n","\n","JOCK: Why not?\n","\n","\t\t\tThe servant, who was waiting in the dark, and was watching me closely, saw the box at the foot of the table, and opened it to me.\n","\n","\t\t\tIt was a little piece of wood upon the table above the coffin. It was a beautiful piece of red wood, with a white top and a black patch. It was round, proportioned, and sat in the place where the body lay, to the left of the coffin. It had all the same features. And now, now, what if I were to be at peace?\n","\n","I put the box into the servant's arm.\n","\n","\t\t\tHere it was. I thought of one thing I wished to examine; and I could no longer be at peace. My spirits were elevated above all the horrors of death. It was as though, as I sat there, I had fallen asleep. I tried to wake, but, while I was, I felt that my heart had not taken me under its effect, and I did not know the cause of that. I wished it was not so.\n","\n","\t\t\tOne piece of wood had fallen upon the coffin, and it lay again at my father's feet.\n","\n","\t\t\tOn the stone, the face of which was of dark browner colour;\n","\n","that stood there by the fire, was a lump. If I had been a man,\n","\n","that face would not have been on my coffin. Its cheeks were white as the fire,\n","and the hairs of its body stood in its mouth. Here and there were wounds, and in these we have seen\n","to-day. It was the same face that the devil had given us on the brink of death,\n","if I had been alive.\n","\n","\t\t\tIt was almost all of the same material, of which I had seen many. And the faces of the other parts were also of that same material, so also I looked forward to seeing the face that I found myself in a dream.\n","\n","\t\t\tBut still the face of the monster was alive. The face that lay upon the coffin, standing on its haunches, to the left and on either side\n","of the coffin.\n","\n","\t\t\tThe creature had made a name for herself at first sight; it had been a monster. But it was also of a spirit, a being with an air of horror, and with a passion for death to be taken\n","back, that it would lead her down to her murderer, and to his body, and to the body of the fiend, the one who had possessed the house, that I\n","will remember to this day. I am no monster, only a man, or a spirit.\n","\n","As I was sitting there, I heard a voice, which was the same as the one that had come in to my father's side. I sat by the table; it was the same one that had come, to sit at my father's feet; it was a tallish figure, of the same color,\n","and quite different from\n","\n","[410 | 1797.46] loss=2.87 avg=2.81\n","[420 | 1839.85] loss=2.47 avg=2.80\n","[430 | 1882.26] loss=2.13 avg=2.78\n","[440 | 1924.70] loss=2.53 avg=2.77\n","[450 | 1967.19] loss=2.63 avg=2.77\n","[460 | 2009.76] loss=3.25 avg=2.78\n","[470 | 2052.39] loss=1.65 avg=2.75\n","[480 | 2095.07] loss=2.72 avg=2.75\n","[490 | 2137.62] loss=2.32 avg=2.74\n","[500 | 2180.22] loss=3.11 avg=2.75\n","Saving checkpoint/run1_novels/model-500\n","[510 | 2225.88] loss=2.63 avg=2.75\n","[520 | 2268.38] loss=2.49 avg=2.74\n","[530 | 2310.65] loss=2.51 avg=2.73\n","[540 | 2352.96] loss=3.00 avg=2.74\n","[550 | 2395.22] loss=2.54 avg=2.74\n","[560 | 2437.50] loss=2.87 avg=2.74\n","[570 | 2479.66] loss=2.47 avg=2.73\n","[580 | 2522.30] loss=2.61 avg=2.73\n","[590 | 2564.97] loss=2.63 avg=2.73\n","[600 | 2607.65] loss=2.82 avg=2.73\n","======== SAMPLE 1 ========\n"," child and the child did not care about him, and she only worried about the money and getting them to come to America. When the money arrived, the children had to come. When the money finally came, too, it was good.\n","\n","“This—it’s all a big lie!” she said.\n","\n","“We saved the family,” she said, “because we forgot to take our medicines and make the babies.”\n","\n","I did not. I had no interest in what she had to say. It was the work of my imagination. At that moment, I realized what had happened to Diana. I saw through the lies she was having to tell—and I told her what I knew—and I told her what she wanted.\n","\n","I put the silver box on the table and sat down. It was a big, dark box, with a very large key-release mechanism. I had heard, or ought to have seen, that the key held a crystal that could be broken or flipped. I had seen the key before, it was a tiny crystal. But it held no secrets! The crystal was hidden in a glass jar. We were able to take a look, after the child had come to, that could reveal the identity of the person inside.\n","\n","“What do you want, Mrs. Poole?” Diana asked me when we were alone and when I returned at last as Mrs. Poole.\n","\n","“I don’t know,” I said firmly.\n","\n","I had seen Diana’s picture before, and I knew there were more faces for me to see. “But it was for you, Mrs. Poole. Can you ask how long she has been in London, without you seeing her?” I stared.\n","\n","We stood back and took a long walk along Hammersmith Green. At twilight, I listened to the soft music of the Cats, as it came on. It was the night before that Miss Diana had disappeared, and the night after that was that which was not for the children, to be found and brought home again. Diana had not been anywhere.\n","\n","“Oh, and we’re sure it was for you,” said Mrs. Poole.\n","\n","“What are you talking about?” I asked her.\n","\n","“You can help me, I only suggest you let me know the answer.” She looked up at me again, looking very pale in her light. “You think she might come.”\n","\n","“I thought she went, Diana, just yesterday, I hope, so, all of us, you don’t know what happened yesterday.”\n","\n","“It’s just the sort of thing that happens everywhere else,” said Diana, looking tired. “But she’s in the wrong house or somewhere.”\n","\n","“Yes, and she’s in the wrong place too. The housekeeper said the girls were going to be here, and it just won’t take long.”\n","\n","“Well, of course she can take them and come. But how can I go, you ask me.”\n","\n","“Just one minute, Mrs. Poole, how long have you been in London?”\n","\n","“Three, five, ten minutes, I know, I don’t know what time it is.” I hesitated.\n","\n","“And you don’t know what it is, Mrs. Poole?”\n","\n","“No, thank you, Miss.”\n","\n","Mrs. Poole said something. “You think I’m talking to you?” I knew she was going to ask me how long it had been since last she had last seen, if I could tell her.\n","\n","“That won’t be me for long,” I said weakly. “Mrs. Poole, I’m coming back again, you know.”\n","\n","“Then how much time do you think it must be?”\n","\n","“Well, Mrs. Poole, it shouldn’t have been me. I would, I think, have been lying about it, for Mrs. Poole, if something like that ever happened to Miss Lestrade.\n","\n","“Then we shouldn’t believe them, you know?” I shook my head, a smile on my face. “It’s all the same. They would have said something about Miss Lestrade.”\n","\n","“What do you mean, Mrs. Poole?”\n","\n","“Well, I’m not going, sorry. I’m not sorry. That’s all the\n","\n","[610 | 2669.33] loss=2.54 avg=2.72\n","[620 | 2711.95] loss=2.63 avg=2.72\n","[630 | 2754.52] loss=3.19 avg=2.73\n","[640 | 2797.14] loss=2.85 avg=2.74\n","[650 | 2839.70] loss=2.84 avg=2.74\n","[660 | 2882.01] loss=1.98 avg=2.72\n","[670 | 2924.32] loss=2.80 avg=2.72\n","[680 | 2966.69] loss=2.68 avg=2.72\n","[690 | 3009.07] loss=3.09 avg=2.73\n","[700 | 3051.39] loss=2.44 avg=2.72\n","[710 | 3093.69] loss=2.55 avg=2.72\n","[720 | 3136.05] loss=2.54 avg=2.72\n","[730 | 3178.37] loss=2.75 avg=2.72\n","[740 | 3220.68] loss=2.01 avg=2.70\n","[750 | 3263.02] loss=2.37 avg=2.70\n","[760 | 3305.35] loss=2.76 avg=2.70\n","[770 | 3347.71] loss=2.89 avg=2.70\n","[780 | 3390.00] loss=3.15 avg=2.71\n","[790 | 3432.29] loss=2.34 avg=2.70\n","[800 | 3474.59] loss=2.83 avg=2.71\n","======== SAMPLE 1 ========\n"," she was born and raised in one of those rural parts of England you can often find there—a small village—where those of a more cultivated kind generally live. It was only by the way that I have been out of the world, and had seen a lot of stars. They were small and bright enough not to matter so much as a little with me the other night. I had looked in the mirror. It was already dark.\n","\n","\t\tWhen I was young—and perhaps by now only two years old—the father of my brother, in my ignorance of our society and feelings, had come to us to tell us of the other woman he had seen. He had been called Elizabeth, or simply Elizabeth Lavenza. Her portrait had been taken, it was said, by one of her neighbors. You could find it hanging in a barn in Walton Street, just off the main street from where we had come, on the wall opposite where he had been sitting. We looked it over, or our eyes opened. The girl of whom I knew, as we spoke, was a girl of about forty years of age, of the same description, with a thin and curly brown hair, and brown eyes—and of a different mother.\n","\n","\t\tWhen Elizabeth saw this portrait in her hand—she said to us, with an expression of pity, “My father loved and adored this creature and she loves him for what he is. Why should he ever give her no gift?”\n","\n","\t\t“She will not; and she will make him a poor man, as the poor woman in the story told of her, her mother, will make him miserable when she does not. And that is a very harsh punishment to her, for she suffered greatly and endured harsh chastity; but she will not.”\n","\n","\t\t“A woman of a certain disposition will make him wretched. She will not; she will make him miserable by marrying and distributing his property among her daughters.”\n","\n","\t\t“A young man, of moderate means, ought to know so little things and to love and love those things that are dear to him, even when the consequences are horrible to his taste and his character. It is an excellent instrument to him, for he has an air of an amusement and a curiosity, that elevates his senses to the highest degree.”\n","\n","\t\t“There is a story of a woman who was married early to a man. The husband was of a good family, although very poor and uncivilized; and she was the youngest of the couple. She was not called Sophia, for her name was not female, but daughter of Agatha, the daughter of the god of the woods. When she was only seven months of age, she had at last married a man of good family, that one of whom the youth to the left might esteem her sister equally. When the youthful woman had married one of the parents of the same child, the bridegroom, or wife, she was afterwards called, as she married, Sophia. Sophia became the daughter of one of the parents of the other of her husband’s daughter, but in reality she was born prematurely, and afterwards abandoned the marriage by her own wickedness. Her marriage with the man who had made her his female partner, was annulled by the woman’s father, who, from a sudden change of fortune, was disgusted with the girl, and she conceived the child of his own free will. The father did not allow her to become his wife or her first heir, but she was destined to be his only.\n","\n","\t\t\t“This girl was not of a good description; but as she was only of a noble birth, so was her mother. Although her father abhorred her, she did not doubt her innocence. She saw him at first sight, but said little, and became miserable as a result. She was called by her mother, who taught her to shut her eyes; but at that age she could not endure the sight of any creature that approached her from the dark and dismal world of human shape, and she thought she herself very dumb.\n","\n","\t\t\t“After having married, and having formed a family of the most excellent kind in the neighbourhood of England, she was left to herself, by a man chosen by her, to live by pleasure and luxury. This, in my judgment, was the very birth of happiness. The young man, who, although beautiful and excellent, might afford her the greatest luxury but a few moments” the poverty which she endured: and, instead of following his example, she gave an abortive effort, and endeavoured as she might to destroy in every possible way those who might associate with her the poverty that she endured.\n","\n","\n","\n","\n","\n","Chapter III\n","\n","\n","\n","\n","\t\t\t“‘The young man. She.’s my sister.’\n","\n","\n","\n","I was a little startled to hear this. He was\n","\n","[810 | 3536.03] loss=1.70 avg=2.69\n","[820 | 3578.61] loss=2.25 avg=2.68\n","[830 | 3621.24] loss=1.85 avg=2.67\n","[840 | 3663.89] loss=2.18 avg=2.66\n","[850 | 3706.51] loss=2.45 avg=2.65\n","[860 | 3749.15] loss=2.14 avg=2.64\n","[870 | 3791.84] loss=2.45 avg=2.64\n","[880 | 3834.53] loss=2.39 avg=2.64\n","[890 | 3877.20] loss=2.08 avg=2.63\n","[900 | 3919.87] loss=2.29 avg=2.62\n","[910 | 3962.53] loss=2.82 avg=2.63\n","[920 | 4005.08] loss=2.30 avg=2.62\n","[930 | 4047.77] loss=2.22 avg=2.61\n","[940 | 4090.15] loss=2.74 avg=2.62\n","[950 | 4132.50] loss=2.27 avg=2.61\n","[960 | 4174.86] loss=2.56 avg=2.61\n","[970 | 4217.19] loss=2.83 avg=2.61\n","[980 | 4259.51] loss=2.37 avg=2.61\n","[990 | 4301.87] loss=2.58 avg=2.61\n","[1000 | 4344.19] loss=2.64 avg=2.61\n","Saving checkpoint/run1_novels/model-1000\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py:1058: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to delete files with this prefix.\n"]}]},{"cell_type":"markdown","metadata":{"id":"IXSuTNERaw6K"},"source":["After the model is trained, you can copy the checkpoint folder to your own Google Drive.\n","\n","If you want to download it to your personal computer, it's strongly recommended you copy it there first, then download from Google Drive. The checkpoint folder is copied as a `.rar` compressed file; you can download it and uncompress it locally."]},{"cell_type":"code","metadata":{"id":"VHdTL8NDbAh3","executionInfo":{"status":"ok","timestamp":1637338070569,"user_tz":420,"elapsed":4283,"user":{"displayName":"Paolo Verdini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5rOvBH3Z1IIZTEbIoKWAaKG0XkOwI2nfdUeG5lw=s64","userId":"02285138175827045307"}}},"source":["gpt2.copy_checkpoint_to_gdrive(run_name='run1_novels')"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zqplTGFVcqRG","executionInfo":{"status":"ok","timestamp":1637329638454,"user_tz":420,"elapsed":24153,"user":{"displayName":"Paolo Verdini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5rOvBH3Z1IIZTEbIoKWAaKG0XkOwI2nfdUeG5lw=s64","userId":"02285138175827045307"}},"outputId":"ef3eab7f-1e80-44ac-eb23-a679b382675d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"qQJgV_b4bmzd"},"source":["You're done! Feel free to go to the **Generate Text From The Trained Model** section to generate text based on your retrained model."]},{"cell_type":"markdown","metadata":{"id":"pel-uBULXO2L"},"source":["## Load a Trained Model Checkpoint\n","\n","Running the next cell will copy the `.rar` checkpoint file from your Google Drive into the Colaboratory VM."]},{"cell_type":"code","metadata":{"id":"DCcx5u7sbPTD"},"source":["gpt2.copy_checkpoint_from_gdrive(run_name='run1_all')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RTa6zf3e_9gV"},"source":["The next cell will allow you to load the retrained model checkpoint + metadata necessary to generate text.\n","\n","**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files."]},{"cell_type":"code","metadata":{"id":"-fxL77nvAMAX"},"source":["sess = gpt2.start_tf_sess()\n","gpt2.load_gpt2(sess, run_name='run1_all')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ClJwpF_ACONp"},"source":["## Generate Text From The Trained Model\n","\n","After you've trained the model or loaded a retrained model from checkpoint, you can now generate text. `generate` generates a single text from the loaded model."]},{"cell_type":"code","metadata":{"id":"4RNY6RBI9LmL","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1637329933218,"user_tz":420,"elapsed":4739,"user":{"displayName":"Paolo Verdini","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi5rOvBH3Z1IIZTEbIoKWAaKG0XkOwI2nfdUeG5lw=s64","userId":"02285138175827045307"}},"outputId":"0fcc7621-eade-4760-944d-e106ab751065"},"source":["gpt2.generate(sess, run_name='run1_all')"],"execution_count":null,"outputs":[{"output_type":"error","ename":"FailedPreconditionError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1379\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1363\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1364\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1457\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFailedPreconditionError\u001b[0m: 2 root error(s) found.\n  (0) FAILED_PRECONDITION: Could not find variable model/h5/mlp/c_proj/w. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status error message=Container localhost does not exist. (Could not find resource: localhost/model/h5/mlp/c_proj/w)\n\t [[{{node sample_sequence_1/model/h5/mlp/c_proj/Reshape_1/ReadVariableOp}}]]\n\t [[strided_slice_3/_33]]\n  (1) FAILED_PRECONDITION: Could not find variable model/h5/mlp/c_proj/w. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status error message=Container localhost does not exist. (Could not find resource: localhost/model/h5/mlp/c_proj/w)\n\t [[{{node sample_sequence_1/model/h5/mlp/c_proj/Reshape_1/ReadVariableOp}}]]\n0 successful operations.\n0 derived errors ignored.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-4367814bedb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'run1_all'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gpt_2_simple/gpt_2.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(sess, run_name, checkpoint_dir, model_name, model_dir, sample_dir, return_as_list, truncate, destination_path, sample_delim, prefix, seed, nsamples, batch_size, length, temperature, top_k, top_p, include_prefix)\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mgenerated\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnsamples\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             out = sess.run(output, feed_dict={\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 971\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    972\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1192\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1194\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1195\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1372\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1374\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1375\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1376\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1397\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1399\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=no-value-for-parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFailedPreconditionError\u001b[0m: 2 root error(s) found.\n  (0) FAILED_PRECONDITION: Could not find variable model/h5/mlp/c_proj/w. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status error message=Container localhost does not exist. (Could not find resource: localhost/model/h5/mlp/c_proj/w)\n\t [[node sample_sequence_1/model/h5/mlp/c_proj/Reshape_1/ReadVariableOp\n (defined at /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/model.py:85)\n]]\n\t [[strided_slice_3/_33]]\n  (1) FAILED_PRECONDITION: Could not find variable model/h5/mlp/c_proj/w. This could mean that the variable has been deleted. In TF1, it can also mean the variable is uninitialized. Debug info: container=localhost, status error message=Container localhost does not exist. (Could not find resource: localhost/model/h5/mlp/c_proj/w)\n\t [[node sample_sequence_1/model/h5/mlp/c_proj/Reshape_1/ReadVariableOp\n (defined at /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/model.py:85)\n]]\n0 successful operations.\n0 derived errors ignored.\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sample_sequence_1/model/h5/mlp/c_proj/Reshape_1/ReadVariableOp:\nIn[0] model/h5/mlp/c_proj/w (defined at /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/model.py:83)\n\nOperation defined at: (most recent call last)\n>>>   File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n>>>     \"__main__\", mod_spec)\n>>> \n>>>   File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n>>>     handler_func(fileobj, events)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n>>>     self._handle_recv()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n>>>     self._run_callback(callback, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n>>>     callback(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n>>>     return self.dispatch_shell(stream, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n>>>     handler(stream, idents, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n>>>     user_expressions, allow_stdin)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n>>>     interactivity=interactivity, compiler=compiler, result=result)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n>>>     if self.run_code(code, result):\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-11-4367814bedb4>\", line 1, in <module>\n>>>     gpt2.generate(sess, run_name='run1_all')\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/gpt_2_simple/gpt_2.py\", line 468, in generate\n>>>     temperature=temperature, top_k=top_k, top_p=top_p\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py\", line 67, in sample_sequence\n>>>     context_output = step(hparams, context[:, :-1])\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py\", line 52, in step\n>>>     past=past, reuse=tf.compat.v1.AUTO_REUSE)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/model.py\", line 203, in model\n>>>     h, present = block(h, 'h%d' % layer, past=past, hparams=hparams)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/model.py\", line 158, in block\n>>>     m = mlp(norm(x, 'ln_2'), 'mlp', nx*4, hparams=hparams)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/model.py\", line 149, in mlp\n>>>     h2 = conv1d(h, 'c_proj', nx)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/model.py\", line 85, in conv1d\n>>>     c = tf.reshape(tf.matmul(tf.reshape(x, [-1, nx]), tf.reshape(w, [-1, nf]))+b, start+[nf])\n>>> \n\nInput Source operations connected to node sample_sequence_1/model/h5/mlp/c_proj/Reshape_1/ReadVariableOp:\nIn[0] model/h5/mlp/c_proj/w (defined at /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/model.py:83)\n\nOperation defined at: (most recent call last)\n>>>   File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n>>>     \"__main__\", mod_spec)\n>>> \n>>>   File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n>>>     handler_func(fileobj, events)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n>>>     self._handle_recv()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n>>>     self._run_callback(callback, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n>>>     callback(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n>>>     return self.dispatch_shell(stream, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n>>>     handler(stream, idents, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n>>>     user_expressions, allow_stdin)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n>>>     interactivity=interactivity, compiler=compiler, result=result)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n>>>     if self.run_code(code, result):\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-11-4367814bedb4>\", line 1, in <module>\n>>>     gpt2.generate(sess, run_name='run1_all')\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/gpt_2_simple/gpt_2.py\", line 468, in generate\n>>>     temperature=temperature, top_k=top_k, top_p=top_p\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py\", line 67, in sample_sequence\n>>>     context_output = step(hparams, context[:, :-1])\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py\", line 52, in step\n>>>     past=past, reuse=tf.compat.v1.AUTO_REUSE)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/model.py\", line 203, in model\n>>>     h, present = block(h, 'h%d' % layer, past=past, hparams=hparams)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/model.py\", line 158, in block\n>>>     m = mlp(norm(x, 'ln_2'), 'mlp', nx*4, hparams=hparams)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/model.py\", line 149, in mlp\n>>>     h2 = conv1d(h, 'c_proj', nx)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/model.py\", line 85, in conv1d\n>>>     c = tf.reshape(tf.matmul(tf.reshape(x, [-1, nx]), tf.reshape(w, [-1, nf]))+b, start+[nf])\n>>> \n\nOriginal stack trace for 'sample_sequence_1/model/h5/mlp/c_proj/Reshape_1/ReadVariableOp':\n  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-4367814bedb4>\", line 1, in <module>\n    gpt2.generate(sess, run_name='run1_all')\n  File \"/usr/local/lib/python3.7/dist-packages/gpt_2_simple/gpt_2.py\", line 468, in generate\n    temperature=temperature, top_k=top_k, top_p=top_p\n  File \"/usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py\", line 67, in sample_sequence\n    context_output = step(hparams, context[:, :-1])\n  File \"/usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py\", line 52, in step\n    past=past, reuse=tf.compat.v1.AUTO_REUSE)\n  File \"/usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/model.py\", line 203, in model\n    h, present = block(h, 'h%d' % layer, past=past, hparams=hparams)\n  File \"/usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/model.py\", line 158, in block\n    m = mlp(norm(x, 'ln_2'), 'mlp', nx*4, hparams=hparams)\n  File \"/usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/model.py\", line 149, in mlp\n    h2 = conv1d(h, 'c_proj', nx)\n  File \"/usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/model.py\", line 85, in conv1d\n    c = tf.reshape(tf.matmul(tf.reshape(x, [-1, nx]), tf.reshape(w, [-1, nf]))+b, start+[nf])\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\", line 1096, in op_dispatch_handler\n    return dispatch_target(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 197, in reshape\n    result = gen_array_ops.reshape(tensor, shape, name)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 8547, in reshape\n    \"Reshape\", tensor=tensor, shape=shape, name=name)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 517, in _apply_op_helper\n    preferred_dtype=default_dtype)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1621, in convert_to_tensor\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 2063, in _dense_var_to_tensor\n    return var._dense_var_to_tensor(dtype=dtype, name=name, as_ref=as_ref)  # pylint: disable=protected-access\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 1441, in _dense_var_to_tensor\n    return self.value()\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 590, in value\n    return self._read_variable_op()\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 699, in _read_variable_op\n    result = read_and_set_handle()\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\", line 690, in read_and_set_handle\n    self.handle, self._dtype)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_resource_variable_ops.py\", line 485, in read_variable_op\n    \"ReadVariableOp\", resource=resource, dtype=dtype, name=name)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 746, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 3705, in _create_op_internal\n    op_def=op_def)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 2101, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n"]}]},{"cell_type":"markdown","metadata":{"id":"oF4-PqF0Fl7R"},"source":["If you're creating an API based on your model and need to pass the generated text elsewhere, you can do `text = gpt2.generate(sess, return_as_list=True)[0]`\n","\n","You can also pass in a `prefix` to the generate function to force the text to start with a given character sequence and generate text from there (good if you add an indicator when the text starts).\n","\n","You can also generate multiple texts at a time by specifing `nsamples`. Unique to GPT-2, you can pass a `batch_size` to generate multiple samples in parallel, giving a massive speedup (in Colaboratory, set a maximum of 20 for `batch_size`).\n","\n","Other optional-but-helpful parameters for `gpt2.generate` and friends:\n","\n","*  **`length`**: Number of tokens to generate (default 1023, the maximum)\n","* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n","* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n","* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)\n","* **`truncate`**: Truncates the input text until a given sequence, excluding that sequence (e.g. if `truncate='<|endoftext|>'`, the returned text will include everything before the first `<|endoftext|>`). It may be useful to combine this with a smaller `length` if the input texts are short.\n","*  **`include_prefix`**: If using `truncate` and `include_prefix=False`, the specified `prefix` will not be included in the returned text."]},{"cell_type":"code","metadata":{"id":"8DKMc0fiej4N"},"source":["gpt2.generate(sess,\n","              length=250,\n","              temperature=0.7,\n","              prefix=\"ethical AI can be developed when\",\n","              nsamples=5,\n","              batch_size=5\n","              )"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zjjEN2Tafhl2"},"source":["For bulk generation, you can generate a large amount of text to a file and sort out the samples locally on your computer. The next cell will generate a generated text file with a unique timestamp.\n","\n","You can rerun the cells as many times as you want for even more generated texts!"]},{"cell_type":"code","metadata":{"id":"Fa6p6arifSL0"},"source":["gen_file = 'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow())\n","\n","gpt2.generate_to_file(sess,\n","                      destination_path=gen_file,\n","                      length=500,\n","                      temperature=0.7,\n","                      nsamples=100,\n","                      batch_size=20\n","                      )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0-LRex8lfv1g"},"source":["# may have to run twice to get file to download\n","files.download(gen_file)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QQAN3M6RT7Kj"},"source":["## Generate Text From The Pretrained Model\n","\n","If you want to generate text from the pretrained model, not a finetuned model, pass `model_name` to `gpt2.load_gpt2()` and `gpt2.generate()`.\n","\n","This is currently the only way to generate text from the 774M or 1558M models with this notebook."]},{"cell_type":"code","metadata":{"id":"hsUd_jHgUZnD","colab":{"base_uri":"https://localhost:8080/"},"outputId":"e0a0a5f7-f612-460e-86a7-a3e8b63c1009"},"source":["model_name = \"774M\"\n","\n","gpt2.download_gpt2(model_name=model_name)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Fetching checkpoint: 1.05Mit [00:00, 205Mit/s]                                                      \n","Fetching encoder.json: 1.05Mit [00:00, 7.23Mit/s]\n","Fetching hparams.json: 1.05Mit [00:00, 557Mit/s]                                                    \n","Fetching model.ckpt.data-00000-of-00001: 3.10Git [01:15, 40.9Mit/s]                                 \n","Fetching model.ckpt.index: 1.05Mit [00:00, 547Mit/s]                                                \n","Fetching model.ckpt.meta: 2.10Mit [00:00, 6.82Mit/s]                                                \n","Fetching vocab.bpe: 1.05Mit [00:00, 4.08Mit/s]\n"]}]},{"cell_type":"code","metadata":{"id":"BAe4NpKNUj2C","colab":{"base_uri":"https://localhost:8080/","height":392},"outputId":"cf42fcfe-a907-429e-cd0f-a1a6b6b03037"},"source":["sess = gpt2.start_tf_sess()\n","\n","gpt2.load_gpt2(sess, model_name=model_name)"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-e8a3f5c6cb77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_tf_sess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_gpt2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gpt_2_simple/gpt_2.py\u001b[0m in \u001b[0;36mload_gpt2\u001b[0;34m(sess, checkpoint, run_name, checkpoint_dir, model_name, model_dir, multi_gpu, reuse)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[0mgpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_available_gpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'latest'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/model.py\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(hparams, X, past, scope, gpus, reuse)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         wpe = tf.compat.v1.get_variable('wpe', [hparams.n_ctx, hparams.n_embd],\n\u001b[0;32m--> 189\u001b[0;31m                              initializer=tf.compat.v1.random_normal_initializer(stddev=0.01))\n\u001b[0m\u001b[1;32m    190\u001b[0m         wte = tf.compat.v1.get_variable('wte', [hparams.n_vocab, hparams.n_embd],\n\u001b[1;32m    191\u001b[0m                              initializer=tf.compat.v1.random_normal_initializer(stddev=0.02))\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1593\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1594\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1595\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1336\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1338\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1340\u001b[0m   def _get_partitioned_variable(self,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    591\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m   def _get_partitioned_variable(self,\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    543\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     synchronization, aggregation, trainable = (\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[0;31m# ResourceVariables don't have an op associated with so no traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_variable_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResourceVariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 887\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    888\u001b[0m         \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0;31m# Throw away internal tf entries and only take a few lines. In some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Variable model/wpe already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope?"]}]},{"cell_type":"code","metadata":{"id":"-xInIZKaU104","colab":{"base_uri":"https://localhost:8080/","height":232},"outputId":"f5ce332a-faab-4534-ae9c-5efae4ee176e"},"source":["gpt2.generate(sess,\n","              model_name=model_name,\n","              prefix=\"The secret of life is\",\n","              length=100,\n","              temperature=0.7,\n","              top_p=0.9,\n","              nsamples=5,\n","              batch_size=5\n","              )"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-140a307abd17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m gpt2.generate(sess,\n\u001b[0;32m----> 2\u001b[0;31m               \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m               \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"The secret of life is\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m               \u001b[0mtemperature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'model_name' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"ig-KVgkCDCKD"},"source":["# Etcetera\n","\n","If the notebook has errors (e.g. GPU Sync Fail), force-kill the Colaboratory virtual machine and restart it with the command below:"]},{"cell_type":"code","metadata":{"id":"rIHiVP53FnsX"},"source":["!kill -9 -1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wmTXWNUygS5E"},"source":["# LICENSE\n","\n","MIT License\n","\n","Copyright (c) 2019 Max Woolf\n","\n","Permission is hereby granted, free of charge, to any person obtaining a copy\n","of this software and associated documentation files (the \"Software\"), to deal\n","in the Software without restriction, including without limitation the rights\n","to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n","copies of the Software, and to permit persons to whom the Software is\n","furnished to do so, subject to the following conditions:\n","\n","The above copyright notice and this permission notice shall be included in all\n","copies or substantial portions of the Software.\n","\n","THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n","IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n","FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n","AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n","LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n","OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n","SOFTWARE."]}]}